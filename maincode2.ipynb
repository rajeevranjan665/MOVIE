{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNiSFzX9w3QT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "movies = pd.read_csv('/content/tmdb_5000_movies.csv')\n",
        "credits = pd.read_csv('/content/tmdb_5000_credits.csv')\n",
        "movies.head()\n",
        "credits.head()\n",
        "movies = movies.merge(credits,on='title')\n",
        "movies.head()\n",
        "print(movies.columns)\n",
        "movies = movies['original_language'].value_counts()\n",
        "movies.info()\n",
        "import pandas as pd\n",
        "\n",
        "# Load the datasets\n",
        "movies = pd.read_csv('/content/tmdb_5000_movies.csv')\n",
        "credits = pd.read_csv('/content/tmdb_5000_credits.csv')\n",
        "\n",
        "# Merge the datasets on 'title'\n",
        "movies = movies.merge(credits, on='title')\n",
        "\n",
        "# Now extract the required columns\n",
        "movies = movies[['movie_id', 'cast', 'crew', 'title', 'overview', 'genres', 'keywords']]\n",
        "\n",
        "# Check the output\n",
        "print(movies.head())\n",
        "movies.isnull().sum()\n",
        "movies.dropna(inplace = True)\n",
        "movies.duplicated().sum()\n",
        "movies.iloc[0].genres\n",
        "import ast\n",
        "def convert(obj):\n",
        "    L=[]\n",
        "    for i in ast.literal_eval(obj):\n",
        "        L.append(i['name'])\n",
        "        return L\n",
        "movies['genres'] = movies['genres'].apply(convert)\n",
        "movies.head()    \n",
        "movies['keywords'] = movies['keywords'].apply(convert)\n",
        "movies.head()\n",
        "movies['cast'][0]\n",
        "from typing import Counter\n",
        "def convert3(obj):\n",
        "    L=[]\n",
        "    Counter = 0\n",
        "    for i in ast.literal_eval(obj):\n",
        "      if Counter != 3:\n",
        "        L.append(i['name'])\n",
        "        Counter+=1\n",
        "      else:\n",
        "        break\n",
        "    return L\n",
        "movies['cast'] = movies['cast'].apply(convert3)\n",
        "movies.head()\n",
        "movies['crew'][0]\n",
        "def fetch_director(obj):\n",
        "    L=[]\n",
        "    for i in ast.literal_eval(obj):\n",
        "      if i['job'] == 'Director':\n",
        "        L.append(i['name'])\n",
        "      else:\n",
        "        break\n",
        "    return L\n",
        "movies['crew'] = movies['crew'].apply(fetch_director)\n",
        "movies.head()\n",
        "movies['overview'][0]\n",
        "movies['overview'] = movies['overview'].apply(lambda x: x.split() if isinstance(x, str) else x)\n",
        "movies.head()\n",
        "movies['genres'] = movies['genres'].apply(lambda x: [i.replace(\" \",\"\") for i in x] if isinstance(x, list) else x)\n",
        "movies['keywords'] = movies['keywords'].apply(lambda x: [i.replace(\" \",\"\") for i in x] if isinstance(x, list) else x)\n",
        "movies['cast'] = movies['cast'].apply(lambda x: [i.replace(\" \",\"\") for i in x] if isinstance(x, list) else x)\n",
        "movies['crew'] = movies['crew'].apply(lambda x: [i.replace(\" \",\"\") for i in x] if isinstance(x, list) else x)\n",
        "movies.head()\n",
        "movies['tags'] = movies['overview'] + movies['genres'] + movies['keywords'] + movies['cast'] + movies['crew']\n",
        "new_df = movies[['movie_id','title','tags']]\n",
        "new_df\n",
        "new_df['tags'] = new_df['tags'].apply(lambda x: \" \".join(x) if isinstance(x, list) else \"\")\n",
        "new_df.head()\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer(max_features=5000,stop_words='english')\n",
        "vector = cv.fit_transform(new_df['tags']).toarray()\n",
        "vector[0]\n",
        "cv.get_feature_names_out()\n",
        "import nltk\n",
        "!pip install nltk\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "def stem(text):\n",
        "    y = []\n",
        "    for i in text.split():\n",
        "      y.append(ps.stem(i))\n",
        "    return \" \".join(y)\n",
        "new_df['tags'] = new_df['tags'].apply(stem)\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "similarity = cosine_similarity(vector)\n",
        "similarity[0]\n",
        "sorted(list(enumerate(similarity[0])),reverse=True,key=lambda x:x[1])[1:6]\n",
        "def recommend(movie):\n",
        "    movie_index = new_df[new_df['title'] == movie].index[0]\n",
        "    distances = similarity[movie_index]\n",
        "    movies_list = sorted(list(enumerate(distances)),reverse=True,key=lambda x:x[1])[1:6]\n",
        "\n",
        "    for i in movies_list:\n",
        "        print(new_df.iloc[i[0]].title)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
